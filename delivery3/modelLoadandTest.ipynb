{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps \"xformers<0.0.26\" trl peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"model_name\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import openpyxl\n",
    "\n",
    "# Tokenizer ve modeli yükleyin\n",
    "#tokenizer = AutoTokenizer.from_pretrained('modelinizin_yolu')\n",
    "#model = AutoModelForCausalLM.from_pretrained('modelinizin_yolu').to('cuda')\n",
    "\n",
    "# TextStreamer nesnesini oluşturun\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "\n",
    "# Excel dosyasını yükleyin\n",
    "wb = openpyxl.load_workbook('NLP Tablo.xlsx')\n",
    "sheet = wb.active\n",
    "\n",
    "# Excel dosyasındaki verileri kullanarak modeli çalıştırın\n",
    "for row in range(2, sheet.max_row):\n",
    "    # Excel dosyasından instruction ve input alın\n",
    "    instruction = sheet[f'B{row}'].value\n",
    "    input_text = sheet[f'C{row}'].value\n",
    "\n",
    "    # Model için girdileri hazırlayın\n",
    "    inputs = tokenizer(\n",
    "        [\n",
    "            alpaca_prompt.format(instruction, input_text, \"\")\n",
    "        ],\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # Modeli çalıştırın ve sonuçları alın\n",
    "    outputs = model.generate(**inputs, streamer=text_streamer, max_new_tokens=128)\n",
    "\n",
    "    # Sonuçları decode edin ve Excel dosyasına yazın\n",
    "    # Sonuçları decode edin\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # İlk olarak, sadece modelin ürettiği çıktıyı (output) ayıklayın\n",
    "    output_only = result.split(input_text)[-1].strip()\n",
    "\n",
    "    # Daha sonra, başındaki 'Response:' yazısını silin\n",
    "    final_output = output_only.replace('Response:', '').strip()\n",
    "\n",
    "    # Çıktıyı \"olumlu\", \"olumsuz\" veya \"nötr\" olarak etiketleyin\n",
    "    if \"olumlu\" in final_output.lower():\n",
    "        labeled_output = \"olumlu\"\n",
    "    elif \"olumsuz\" in final_output.lower():\n",
    "        labeled_output = \"olumsuz\"\n",
    "    else:\n",
    "        labeled_output = \"nötr\"\n",
    "\n",
    "    # Son olarak, etiketlenmiş çıktıyı Excel dosyasının F sütununa yazdırın\n",
    "    sheet[f'S{row}'].value = labeled_output\n",
    "\n",
    "    # Eğer instructionlar biterse döngüden çık\n",
    "    if not instruction:\n",
    "        break\n",
    "\n",
    "# Excel dosyasını kaydedin\n",
    "wb.save('New NLP Tablo.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benzerlik kontrolü\n",
    "import openpyxl\n",
    "\n",
    "def kiyasla(excelDosyasi):\n",
    "    # Excel dosyasını aç\n",
    "    workbook = openpyxl.load_workbook(excelDosyasi)\n",
    "    sheet = workbook.active\n",
    "\n",
    "    # Toplamda kaç tane aynı var sayacı\n",
    "    ayni_sayaci = 0\n",
    "\n",
    "    # İlk 251 satıra bak\n",
    "    for satir in range(1, 252):\n",
    "        # T ve U sütunlarını al\n",
    "        kelime_T = sheet.cell(row=satir, column=5).value\n",
    "        kelime_U = sheet.cell(row=satir, column=4).value\n",
    "\n",
    "        # Her iki hücre de doluysa ve büyük-küçük harf duyarlılığı olmadan aynıysa\n",
    "        if kelime_T and kelime_U and kelime_T.lower() == kelime_U.lower():\n",
    "            ayni_sayaci += 1\n",
    "\n",
    "    # Toplamda kaç tane aynı olduğunu ekrana yazdır\n",
    "    print(\"Toplamda {} satırda T ve U sütunları aynı kelimeleri içeriyor.\".format(ayni_sayaci))\n",
    "\n",
    "# Kodu çalıştır\n",
    "kiyasla(\"NLP Tablo.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
